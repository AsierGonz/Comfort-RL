# ML-Agents Robotic Environment Configuration

This configuration file is designed for a robotic environment controlled by ML-Agents. The environment is divided into three distinct phases and contains several configurable parameters that allow adjustment of both the robot's behavior and the interaction with humans and the environment. Below, the main sections of the file and their configurations are explained:

## Configuration File Sections

### Goals
- **precisionGoal**: Defines the target precision with a numerical value (in this case 3.0). This parameter can affect the quality or level of precision expected from the robot when performing certain tasks.

### Penalties
- **activatePenalty**: Enables or disables the use of penalties. If `false`, no penalties are applied during training, whereas if `true`, penalties are activated to guide the agent's behavior.

### Phases
- **startInFirstPhaseOnly, startInSecondPhaseOnly, startInThirdPhaseOnly**: Control whether training should start only in a specific phase.
- **activateThirdPhase**: Activates the third phase, allowing the agent to train in this stage. Each phase has its own characteristics and objectives.

### Human Interaction
- **humanMove**: Indicates whether human movement is involved, moving to different positions each time.
- **personMovement**: If enabled (`true`), the human-person in the environment can move freely during each episode.
- **teleportationDistance**: Defines the teleportation distance for the human in the environment.
- **humanMovementMax**: Specifies the maximum distance a person can move.
- **spawnHuman**: Defines the spawn points for the human. (Choose between 0 and 15) - 

### Environment
- **pinktablePosition, greytablePosition, orangetablePosition**: Specify the positions of the colored tables (pink, grey, and orange) within the environment using `x`, `y`, and `z` coordinates.
- **colorBall**: Indicates the color of the ball with which the agent interacts.
- **routeSaveFile**: Defines the file where the routes generated by the robot are saved.
- **numberOfEnvs**: Number of environments to use during training.

### Comfort Parameters
- **temperature**: Defines the temperature in the robot's environment. - Not important parameter for this release
- **numberOfComfortLevels**: Specifies the number of comfort levels.
- **currentComfortLevel**: Indicates the current comfort level.
- **distanceMaxThreshold**: Defines the maximum distance threshold to maintain comfort. - See paper for better understanding
- **alpha, beta**: Parameters that could be used to adjust comfort based on other values or interactions in the environment.

### Miscellaneous
- **randomStart**: If enabled, allows a random start in the environment. - Not important parameter for this release
- **clipPositionPerson**: Defines whether a person's position should be limited within the environment. - Important for inference or fast trainings -- See code in future releases 
- **singleTrainingOnly**: Indicates if only one training session will be performed. - Important for inference only 
- **checkVR_socket**: Checks for VR connectivity through a socket. - Only important for VR setupts - Future release 1.0
- **saveResults**: Enables or disables saving of results. 
- **numberOfCameras**: Defines the number of cameras in the environment. - Visual
- **pathToSaveRealRobot**: Specifies the file where real robot data is saved. - if save results is true
- **switcher**: Defines whether a specific feature should be activated or deactivated (a general switch). - Important for different NN learning. - See future code release to understand the code

## General Description

This configuration file allows flexible adjustment of how the robotic agent, humans, and elements of the environment interact. Each parameter is intended to customize and optimize the training process, which involves three different phases. Depending on the chosen configuration, one can decide which phase to start in, how the agent will behave, and whether there will be human interaction or additional elements such as colored tables and cameras.

This level of customization helps adjust the agent's behavior according to the desired training objectives, providing the ability to scale the complexity of the environment progressively.
